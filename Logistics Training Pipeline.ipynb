{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "37e7b0ea",
   "metadata": {},
   "source": [
    "# Logistics Training Pipeline (Cleaned)\n",
    "\n",
    "This notebook trains global and carrier-specific LightGBM models to predict shipment **Cost** (log target) and **Transit_Days**,\n",
    "applies **per-carrier calibration**, evaluates performance, and writes Streamlit-friendly artifacts:\n",
    "\n",
    "- `model_artifacts/preprocessor.pkl`  \n",
    "- `model_artifacts/cost_model.pkl`  \n",
    "- `model_artifacts/cost_models_grouped.pkl` (optional carrier-specific)  \n",
    "- `model_artifacts/preprocessor_days.pkl`  \n",
    "- `model_artifacts/transit_days_model.pkl`  \n",
    "- `model_artifacts/best_params.json` (includes features + calibration)  \n",
    "- `model_artifacts/carrier_performance.csv`  \n",
    "- `model_artifacts/carrier_rmse_analysis.png`\n",
    "\n",
    "You can configure data sources via environment variables:\n",
    "\n",
    "- **MySQL (preferred)**: `MYSQL_USER`, `MYSQL_PASSWORD`, `MYSQL_HOST`, `MYSQL_PORT`, `MYSQL_DB`  \n",
    "- **Fallback CSV**: `LOGISTICS_CSV_PATH` (expects columns similar to the sample dataset)\n",
    "\n",
    "Run the final cell to execute `main()`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d98e4d35",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-07 19:17:58,199 - INFO - Env versions: Python 3.13.7 | numpy 2.3.2 | pandas 2.3.1 | sklearn 1.7.1 | lightgbm 4.6.0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import os\n",
    "import json\n",
    "import joblib\n",
    "import logging\n",
    "from datetime import datetime, UTC\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.feature_extraction import FeatureHasher\n",
    "\n",
    "import lightgbm as lgb\n",
    "import optuna\n",
    "import matplotlib.pyplot as plt\n",
    "import platform\n",
    "import sklearn as sk\n",
    "\n",
    "# Threading/parallelism controls — keep training stable\n",
    "os.environ[\"LOKY_MAX_CPU_COUNT\"] = \"1\"\n",
    "os.environ[\"JOBLIB_MULTIPROCESSING\"] = \"0\"\n",
    "os.environ[\"OMP_NUM_THREADS\"] = \"1\"\n",
    "\n",
    "# -------------------------\n",
    "# Logging\n",
    "# -------------------------\n",
    "load_dotenv(\"config.env\")\n",
    "os.makedirs(\"logs\", exist_ok=True)\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format=\"%(asctime)s - %(levelname)s - %(message)s\",\n",
    "    handlers=[\n",
    "        logging.FileHandler(\"logs/logistics_model.log\"),\n",
    "        logging.StreamHandler()\n",
    "    ]\n",
    ")\n",
    "logger = logging.getLogger(__name__)\n",
    "logger.info(\n",
    "    \"Env versions: Python %s | numpy %s | pandas %s | sklearn %s | lightgbm %s\",\n",
    "    platform.python_version(), np.__version__, pd.__version__, sk.__version__, lgb.__version__\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb31ec3d",
   "metadata": {},
   "source": [
    "## Data cleaning & feature engineering helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3f98d25a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def handle_missing_data_smart(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Carrier-aware imputation. Dropping only rows with missing target Cost.\"\"\"\n",
    "    df = df.copy()\n",
    "    initial_count = len(df)\n",
    "    df = df.dropna(subset=['Cost'])\n",
    "    logger.info(\"Removed %d rows with missing Cost\", initial_count - len(df))\n",
    "\n",
    "    critical = ['Distance_miles', 'Weight_kg', 'origin_warehouse', 'Destination', 'Carrier']\n",
    "    for c in critical:\n",
    "        if c not in df.columns:\n",
    "            continue\n",
    "        miss = df[c].isna()\n",
    "        if not miss.any():\n",
    "            continue\n",
    "        logger.info(\"Imputing %d missing values for %s\", int(miss.sum()), c)\n",
    "        for carrier in df['Carrier'].dropna().unique():\n",
    "            m = (df['Carrier'] == carrier) & miss\n",
    "            if not m.any():\n",
    "                continue\n",
    "            if pd.api.types.is_numeric_dtype(df[c]):\n",
    "                val = df.loc[df['Carrier'] == carrier, c].median()\n",
    "            else:\n",
    "                mode = df.loc[df['Carrier'] == carrier, c].mode()\n",
    "                val = mode.iloc[0] if len(mode) else \"Unknown\"\n",
    "            df.loc[m, c] = val\n",
    "\n",
    "    for c in ['origin_warehouse', 'Destination', 'Carrier']:\n",
    "        if c in df.columns:\n",
    "            df[c] = df[c].fillna(\"Unknown\")\n",
    "    return df\n",
    "\n",
    "def detect_and_handle_dhl_outliers(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Cap extreme DHL costs (3*IQR above Q3).\"\"\"\n",
    "    df = df.copy()\n",
    "    dhl_mask = (df['Carrier'] == 'DHL')\n",
    "    if not dhl_mask.any():\n",
    "        return df\n",
    "    dhl_df = df.loc[dhl_mask]\n",
    "    Q1 = dhl_df['Cost'].quantile(0.25)\n",
    "    Q3 = dhl_df['Cost'].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    upper = Q3 + 3 * IQR\n",
    "    extreme = dhl_df[dhl_df['Cost'] > upper]\n",
    "    if len(extreme):\n",
    "        logger.info(\"Capping %d DHL extreme costs at %.2f\", len(extreme), upper)\n",
    "        df.loc[dhl_mask & (df['Cost'] > upper), 'Cost'] = upper\n",
    "    return df\n",
    "\n",
    "def analyze_dhl_data_quality(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Log data quality stats for DHL subset.\"\"\"\n",
    "    dhl_df = df[df['Carrier'] == 'DHL'].copy()\n",
    "    logger.info(\"DHL samples: %d\", len(dhl_df))\n",
    "    for col in ['Distance_miles', 'Weight_kg', 'origin_warehouse', 'Destination']:\n",
    "        if col in dhl_df.columns:\n",
    "            miss = int(dhl_df[col].isna().sum())\n",
    "            pct = (miss / max(len(dhl_df), 1)) if len(dhl_df) else 0.0\n",
    "            logger.info(\"Missing %s: %d (%.1f%%)\", col, miss, pct * 100)\n",
    "    if len(dhl_df):\n",
    "        logger.info(\n",
    "            \"Distance %.0f-%.0f | Weight %.1f-%.1f | Cost %.0f-%.0f\",\n",
    "            dhl_df['Distance_miles'].min(), dhl_df['Distance_miles'].max(),\n",
    "            dhl_df['Weight_kg'].min(), dhl_df['Weight_kg'].max(),\n",
    "            dhl_df['Cost'].min(), dhl_df['Cost'].max()\n",
    "        )\n",
    "    return dhl_df\n",
    "\n",
    "def feature_engineering(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Light, leakage-free features.\"\"\"\n",
    "    df = df.copy()\n",
    "    if 'shipment_date' in df.columns:\n",
    "        dt = pd.to_datetime(df['shipment_date'], errors='coerce')\n",
    "        df['month'] = dt.dt.month.fillna(0).astype(int)\n",
    "        df['day_of_week'] = dt.dt.dayofweek.fillna(0).astype(int)\n",
    "        df['day_of_month'] = dt.dt.day.fillna(0).astype(int)\n",
    "        df['is_weekend'] = (dt.dt.dayofweek >= 5).astype(int)\n",
    "    else:\n",
    "        df['month'] = 0; df['day_of_week'] = 0; df['day_of_month'] = 0; df['is_weekend'] = 0\n",
    "    df['is_holiday_season'] = df['month'].isin([11, 12]).astype(int)\n",
    "    df['route'] = df[\"origin_warehouse\"].astype(str) + \"→\" + df[\"Destination\"].astype(str)\n",
    "    df['is_dhl'] = (df['Carrier'] == 'DHL').astype(int)\n",
    "    df['is_usps'] = (df['Carrier'] == 'USPS').astype(int)\n",
    "    df['is_ups'] = (df['Carrier'] == 'UPS').astype(int)\n",
    "    df['is_fedex'] = (df['Carrier'] == 'FedEx').astype(int)\n",
    "    df['dhl_distance'] = df['is_dhl'] * df['Distance_miles']\n",
    "    df['usps_distance'] = df['is_usps'] * df['Distance_miles']\n",
    "    df['dhl_weight'] = df['is_dhl'] * df['Weight_kg']\n",
    "    df['usps_weight'] = df['is_usps'] * df['Weight_kg']\n",
    "    df['dhl_weekend'] = ((df['Carrier'] == 'DHL') & (df['is_weekend'] == 1)).astype(int)\n",
    "    df['dhl_holiday'] = ((df['Carrier'] == 'DHL') & (df['is_holiday_season'] == 1)).astype(int)\n",
    "    return df\n",
    "\n",
    "def enhanced_dhl_features(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    df = df.copy()\n",
    "    dhl = (df['Carrier'] == 'DHL')\n",
    "    df['dhl_distance_tier'] = 0\n",
    "    if dhl.any():\n",
    "        df.loc[dhl, 'dhl_distance_tier'] = pd.cut(\n",
    "            df.loc[dhl, 'Distance_miles'], bins=[0,500,1000,1500,2000,2500,3000], labels=False\n",
    "        ).astype('float').fillna(0).astype(int)\n",
    "    df['dhl_weight_tier'] = 0\n",
    "    if dhl.any():\n",
    "        df.loc[dhl, 'dhl_weight_tier'] = pd.cut(\n",
    "            df.loc[dhl, 'Weight_kg'], bins=[0,10,20,30,40,50,100], labels=False\n",
    "        ).astype('float').fillna(0).astype(int)\n",
    "    return df\n",
    "\n",
    "def enhanced_dhl_distance_features(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    df = df.copy()\n",
    "    dhl = (df['Carrier'] == 'DHL')\n",
    "    df['dhl_distance_tier_detailed'] = 0\n",
    "    if dhl.any():\n",
    "        df.loc[dhl, 'dhl_distance_tier_detailed'] = pd.cut(\n",
    "            df.loc[dhl, 'Distance_miles'], bins=[0,300,600,900,1200,1500,1800,2100,2400,3000], labels=False\n",
    "        ).astype('float').fillna(0).astype(int)\n",
    "    df['dhl_very_long_distance'] = (dhl & (df['Distance_miles'] > 2000)).astype(int)\n",
    "    df['dhl_distance_squared'] = df['is_dhl'] * (df['Distance_miles'] ** 2)\n",
    "    return df\n",
    "\n",
    "def enhanced_dhl_weight_features(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    df = df.copy()\n",
    "    dhl = (df['Carrier'] == 'DHL')\n",
    "    df['dhl_weight_tier_detailed'] = 0\n",
    "    if dhl.any():\n",
    "        df.loc[dhl, 'dhl_weight_tier_detailed'] = pd.cut(\n",
    "            df.loc[dhl, 'Weight_kg'], bins=[0,5,10,15,20,25,30,35,40,50,100], labels=False\n",
    "        ).astype('float').fillna(0).astype(int)\n",
    "    df['dhl_heavy_package'] = (dhl & (df['Weight_kg'] > 30)).astype(int)\n",
    "    df['dhl_very_heavy_package'] = (dhl & (df['Weight_kg'] > 35)).astype(int)\n",
    "    df['dhl_weight_distance'] = df['is_dhl'] * df['Weight_kg'] * df['Distance_miles']\n",
    "    return df\n",
    "\n",
    "def add_problem_route_features(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    df = df.copy()\n",
    "    problem_routes = [\n",
    "        'Warehouse_CHI→Houston',\n",
    "        'Warehouse_HOU→Chicago',\n",
    "        'Warehouse_MIA→San Francisco',\n",
    "        'Warehouse_ATL→Denver',\n",
    "        'Warehouse_NYC→Phoenix'\n",
    "    ]\n",
    "    df['is_problem_route'] = df['route'].isin(problem_routes).astype(int)\n",
    "    df['is_long_distance_dhl'] = ((df['Carrier'] == 'DHL') & (df['Distance_miles'] > 1900)).astype(int)\n",
    "    df['dhl_long_distance'] = df['is_dhl'] * (df['Distance_miles'] > 1900).astype(int)\n",
    "    df['problem_route_distance'] = df['is_problem_route'] * df['Distance_miles']\n",
    "    return df\n",
    "\n",
    "def enhanced_days_features(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"Placeholder to mirror earlier structure (no leakage here).\"\"\"\n",
    "    return df.copy()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ba3cceb",
   "metadata": {},
   "source": [
    "## Calibration, analysis & prediction helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ce37e6a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def calculate_dynamic_calibration(df_context, y_true, y_pred, target_type='cost'):\n",
    "    \"\"\"Per-carrier median ratio (cost) or mean error (days).\"\"\"\n",
    "    calibration = {}\n",
    "    carriers = pd.Series(df_context['Carrier']).fillna(\"Unknown\").values\n",
    "    for carrier in pd.unique(carriers):\n",
    "        m = (carriers == carrier)\n",
    "        if m.sum() < 5:\n",
    "            continue\n",
    "        a = y_true[m]; p = y_pred[m]\n",
    "        if target_type == 'cost':\n",
    "            with np.errstate(divide='ignore', invalid='ignore'):\n",
    "                ratios = a / p\n",
    "                ratios = ratios[np.isfinite(ratios)]\n",
    "            if len(ratios) > 0:\n",
    "                calibration[carrier] = {'multiplier': float(np.median(ratios))}\n",
    "        else:\n",
    "            calibration[carrier] = {'additive': float(np.mean(a - p))}\n",
    "    return calibration\n",
    "\n",
    "def analyze_dhl_errors(df_val, y_true, y_pred, target_type='cost'):\n",
    "    dhl_mask = (df_val['Carrier'] == 'DHL').to_numpy()\n",
    "    if not dhl_mask.any():\n",
    "        logger.info(\"No DHL samples in validation for analysis\")\n",
    "        return\n",
    "    err = np.abs(y_true[dhl_mask] - y_pred[dhl_mask])\n",
    "    logger.info(\"DHL %s error | mean=%.2f, median=%.2f, max=%.2f\",\n",
    "                target_type, err.mean(), np.median(err), err.max())\n",
    "\n",
    "def handle_problematic_routes(predictions, df_context):\n",
    "    calibrated = np.array(predictions).copy()\n",
    "    route_corrections = {\n",
    "        'Warehouse_CHI→Houston': 0.7,\n",
    "        'Warehouse_HOU→Chicago': 0.8,\n",
    "        'Warehouse_MIA→San Francisco': 0.85,\n",
    "        'Warehouse_ATL→Denver': 0.9,\n",
    "        'Warehouse_NYC→Phoenix': 0.9\n",
    "    }\n",
    "    routes = df_context['route'].astype(str).values\n",
    "    for route, corr in route_corrections.items():\n",
    "        m = (routes == route)\n",
    "        if np.any(m):\n",
    "            calibrated[m] *= corr\n",
    "    m_long = ((df_context['Carrier'] == 'DHL').to_numpy() & (df_context['Distance_miles'].to_numpy() > 1900))\n",
    "    if np.any(m_long):\n",
    "        calibrated[m_long] *= 0.85\n",
    "    return calibrated\n",
    "\n",
    "def apply_calibrated_predictions(model, X_pre, df_context, target_type, calibration_factors):\n",
    "    raw = model.predict(X_pre, num_iteration=getattr(model, \"best_iteration\", None))\n",
    "    if target_type == 'cost':\n",
    "        raw = np.expm1(raw)\n",
    "    calibrated = np.array(raw).copy()\n",
    "    carriers = df_context['Carrier'].fillna(\"Unknown\").values\n",
    "    if calibration_factors:\n",
    "        for carrier, factors in calibration_factors.items():\n",
    "            m = (carriers == carrier)\n",
    "            if not np.any(m):\n",
    "                continue\n",
    "            if target_type == 'cost':\n",
    "                mult = float(factors.get('multiplier', 1.0))\n",
    "                calibrated[m] *= mult\n",
    "            else:\n",
    "                addv = float(factors.get('additive', 0.0))\n",
    "                calibrated[m] += addv\n",
    "    if target_type == 'cost':\n",
    "        calibrated = handle_problematic_routes(calibrated, df_context)\n",
    "    return calibrated\n",
    "\n",
    "def predict_with_dhl_specialized_models(models, X_pre, df_meta, target_type='cost'):\n",
    "    preds = np.zeros(len(df_meta))\n",
    "    dhl_mask = (df_meta['Carrier'] == 'DHL').to_numpy()\n",
    "    if 'dhl_long_distance' in models:\n",
    "        m = dhl_mask & (df_meta['Distance_miles'].to_numpy() > 2000)\n",
    "        idx = np.where(m)[0]\n",
    "        if idx.size:\n",
    "            preds[idx] = models['dhl_long_distance'].predict(X_pre[idx], num_iteration=getattr(models['dhl_long_distance'], \"best_iteration\", None))\n",
    "    if 'dhl_heavy' in models:\n",
    "        m = dhl_mask & (df_meta['Weight_kg'].to_numpy() > 30)\n",
    "        idx = np.where(m)[0]\n",
    "        if idx.size:\n",
    "            preds[idx] = models['dhl_heavy'].predict(X_pre[idx], num_iteration=getattr(models['dhl_heavy'], \"best_iteration\", None))\n",
    "    if 'dhl_normal' in models:\n",
    "        m = dhl_mask & (preds == 0)\n",
    "        idx = np.where(m)[0]\n",
    "        if idx.size:\n",
    "            preds[idx] = models['dhl_normal'].predict(X_pre[idx], num_iteration=getattr(models['dhl_normal'], \"best_iteration\", None))\n",
    "    if target_type == 'cost':\n",
    "        idx = np.where(dhl_mask)[0]\n",
    "        preds[idx] = np.expm1(preds[idx])\n",
    "    return preds\n",
    "\n",
    "def predict_with_carrier_specific_models(models, X_pre, df_meta, target_type='cost'):\n",
    "    preds = np.zeros(len(df_meta))\n",
    "    dhl_models = {k: v for k, v in models.items() if k.startswith('dhl_')}\n",
    "    if dhl_models:\n",
    "        dhl_preds = predict_with_dhl_specialized_models(dhl_models, X_pre, df_meta, target_type)\n",
    "        dhl_mask = (df_meta['Carrier'] == 'DHL').to_numpy()\n",
    "        preds[dhl_mask] = dhl_preds[dhl_mask]\n",
    "    if 'normal' in models and models['normal'] is not None:\n",
    "        normal_carriers = ['UPS', 'FedEx', 'Amazon Logistics', 'LaserShip', 'OnTrac', 'USPS']\n",
    "        m = (df_meta['Carrier'].isin(normal_carriers)).to_numpy() & (preds == 0)\n",
    "        if np.any(m):\n",
    "            yhat = models['normal'].predict(X_pre[m], num_iteration=getattr(models['normal'], \"best_iteration\", None))\n",
    "            if target_type == 'cost':\n",
    "                yhat = np.expm1(yhat)\n",
    "            preds[m] = yhat\n",
    "    return preds\n",
    "\n",
    "def compute_adaptive_weights(global_preds, carrier_preds, y_cost_log, df_meta):\n",
    "    \"\"\"Return dict carrier -> w (weight for global); blend as w*global + (1-w)*carrier.\"\"\"\n",
    "    weights = {}\n",
    "    carriers = df_meta['Carrier'].fillna(\"Unknown\").values\n",
    "    ytrue = np.expm1(y_cost_log.values if hasattr(y_cost_log, 'values') else y_cost_log)\n",
    "    for carrier in pd.unique(carriers):\n",
    "        m = (carriers == carrier)\n",
    "        if m.sum() < 5:\n",
    "            weights[carrier] = 0.5\n",
    "            continue\n",
    "        act = ytrue[m]\n",
    "        g = global_preds[m]\n",
    "        c = carrier_preds[m]\n",
    "        rmse_g = np.sqrt(mean_squared_error(act, g))\n",
    "        rmse_c = np.sqrt(mean_squared_error(act, c))\n",
    "        inv_g = 0.0 if not np.isfinite(rmse_g) or rmse_g <= 0 else 1.0 / rmse_g\n",
    "        inv_c = 0.0 if not np.isfinite(rmse_c) or rmse_c <= 0 else 1.0 / rmse_c\n",
    "        denom = inv_g + inv_c\n",
    "        w = inv_g / denom if denom > 0 else 0.5\n",
    "        weights[carrier] = float(np.clip(w, 0.0, 1.0))\n",
    "    return weights\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb766cd7",
   "metadata": {},
   "source": [
    "## Models & transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c510db4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class RouteHashingEncoder(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"Hash a single 'route' column via sklearn's FeatureHasher.\\n\n",
    "    Expects a Series/array-like of strings. Produces dense array.\"\"\"\n",
    "    def __init__(self, n_features=256):\n",
    "        self.n_features = n_features\n",
    "        self.hasher = FeatureHasher(n_features=n_features, input_type='string')\n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    def transform(self, X):\n",
    "        if isinstance(X, pd.DataFrame):\n",
    "            strings = X.iloc[:, 0].astype(str).tolist()\n",
    "        else:\n",
    "            strings = pd.Series(np.asarray(X).ravel()).astype(str).tolist()\n",
    "        samples = [[s] for s in strings]  # iterable of iterables of strings\n",
    "        mat = self.hasher.transform(samples)\n",
    "        return mat.toarray()\n",
    "\n",
    "def make_ohe():\n",
    "    \"\"\"Sklearn-agnostic OneHotEncoder (sparse_output for >=1.4; fallback to sparse).\"\"\"\n",
    "    try:\n",
    "        return OneHotEncoder(handle_unknown='ignore', sparse_output=False)\n",
    "    except TypeError:\n",
    "        return OneHotEncoder(handle_unknown='ignore', sparse=False)\n",
    "\n",
    "def cv_lightgbm(X, y, params, scoring, cv=5):\n",
    "    scores = []\n",
    "    kf = KFold(n_splits=cv, shuffle=True, random_state=42)\n",
    "    for tr, va in kf.split(X):\n",
    "        Xtr, Xva = X[tr], X[va]\n",
    "        ytr, yva = y[tr], y[va]\n",
    "        dtr = lgb.Dataset(Xtr, label=ytr)\n",
    "        dva = lgb.Dataset(Xva, label=yva)\n",
    "        model = lgb.train(\n",
    "            params, dtr, valid_sets=[dva],\n",
    "            num_boost_round=1000,\n",
    "            callbacks=[lgb.early_stopping(stopping_rounds=50)]\n",
    "        )\n",
    "        if scoring == 'rmse_expm1':\n",
    "            yhat = np.expm1(model.predict(Xva, num_iteration=getattr(model, \"best_iteration\", None)))\n",
    "            score = np.sqrt(mean_squared_error(np.expm1(yva), yhat))\n",
    "        else:\n",
    "            yhat = model.predict(Xva, num_iteration=getattr(model, \"best_iteration\", None))\n",
    "            score = np.sqrt(mean_squared_error(yva, yhat))\n",
    "        scores.append(score)\n",
    "    return np.array(scores)\n",
    "\n",
    "def plot_carrier_rmse(carrier_rmse: pd.DataFrame, output_dir: str):\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
    "    df1 = carrier_rmse.sort_values('RMSE_Cost_Calibrated')\n",
    "    ax1.bar(df1['Carrier'], df1['RMSE_Cost_Calibrated'], alpha=0.7)\n",
    "    ax1.set_title('Cost RMSE (Calibrated) by Carrier')\n",
    "    ax1.set_ylabel('RMSE ($)')\n",
    "    ax1.tick_params(axis='x', rotation=45)\n",
    "    ax1.grid(axis='y', alpha=0.3)\n",
    "    df2 = carrier_rmse.sort_values('RMSE_Transit_Days')\n",
    "    ax2.bar(df2['Carrier'], df2['RMSE_Transit_Days'], alpha=0.7)\n",
    "    ax2.set_title('Transit Days RMSE by Carrier')\n",
    "    ax2.set_ylabel('RMSE (Days)')\n",
    "    ax2.tick_params(axis='x', rotation=45)\n",
    "    ax2.grid(axis='y', alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    plt.savefig(os.path.join(output_dir, \"carrier_rmse_analysis.png\"), dpi=300, bbox_inches=\"tight\")\n",
    "    plt.close()\n",
    "\n",
    "def train_advanced_dhl_model(X_train, y_train):\n",
    "    if len(X_train) < 30:\n",
    "        logger.warning(\"Insufficient DHL data for advanced training\")\n",
    "        return None\n",
    "    params = {\n",
    "        'objective': 'regression', 'metric': 'rmse',\n",
    "        'learning_rate': 0.005, 'num_leaves': 127, 'max_depth': 12,\n",
    "        'min_child_samples': 5, 'feature_fraction': 0.6,\n",
    "        'bagging_fraction': 0.6, 'bagging_freq': 5,\n",
    "        'lambda_l1': 0.5, 'lambda_l2': 0.5, 'min_data_in_leaf': 10, 'verbose': -1\n",
    "    }\n",
    "    dtrain = lgb.Dataset(X_train, label=y_train)\n",
    "    model = lgb.train(params, dtrain, num_boost_round=1000)\n",
    "    return model\n",
    "\n",
    "def train_dhl_specialized_models(X_train, y_train, df_train):\n",
    "    models = {}\n",
    "    y_np = y_train.values if hasattr(y_train, 'values') else y_train\n",
    "    dhl = (df_train['Carrier'] == 'DHL').to_numpy()\n",
    "    long_m = dhl & (df_train['Distance_miles'].to_numpy() > 2000)\n",
    "    if long_m.sum() > 10:\n",
    "        idx = np.where(long_m)[0]\n",
    "        dtr = lgb.Dataset(X_train[idx], label=y_np[idx])\n",
    "        models['dhl_long_distance'] = lgb.train({\n",
    "            'objective': 'regression', 'metric': 'rmse', 'learning_rate': 0.002,\n",
    "            'num_leaves': 15, 'max_depth': 4, 'min_child_samples': 5, 'feature_fraction': 0.8,\n",
    "            'lambda_l1': 1.0, 'lambda_l2': 1.0, 'verbose': -1\n",
    "        }, dtr, num_boost_round=500)\n",
    "    heavy_m = dhl & (df_train['Weight_kg'].to_numpy() > 30)\n",
    "    if heavy_m.sum() > 5:\n",
    "        idx = np.where(heavy_m)[0]\n",
    "        dtr = lgb.Dataset(X_train[idx], label=y_np[idx])\n",
    "        models['dhl_heavy'] = lgb.train({\n",
    "            'objective': 'regression', 'metric': 'rmse', 'learning_rate': 0.005,\n",
    "            'num_leaves': 20, 'max_depth': 5, 'min_child_samples': 3, 'feature_fraction': 0.7,\n",
    "            'lambda_l1': 0.8, 'lambda_l2': 0.8, 'verbose': -1\n",
    "        }, dtr, num_boost_round=300)\n",
    "    normal_m = dhl & (~long_m) & (~heavy_m)\n",
    "    if normal_m.sum() > 20:\n",
    "        idx = np.where(normal_m)[0]\n",
    "        models['dhl_normal'] = train_advanced_dhl_model(X_train[idx], y_np[idx])\n",
    "    return models\n",
    "\n",
    "def train_carrier_specific_models(X_train, y_train, X_val, y_val, df_train, df_val, target_type='cost'):\n",
    "    models = {}\n",
    "    if target_type == 'cost':\n",
    "        models.update(train_dhl_specialized_models(X_train, y_train, df_train))\n",
    "    normal_carriers = ['UPS', 'FedEx', 'Amazon Logistics', 'LaserShip', 'OnTrac', 'USPS']\n",
    "    norm = df_train['Carrier'].isin(normal_carriers).to_numpy()\n",
    "    if norm.any():\n",
    "        Xn = X_train[norm]\n",
    "        yn = (y_train.values if hasattr(y_train, 'values') else y_train)[norm]\n",
    "        vn = df_val['Carrier'].isin(normal_carriers).to_numpy()\n",
    "        Xvn = X_val[vn]\n",
    "        yvn = (y_val.values if hasattr(y_val, 'values') else y_val)[vn]\n",
    "        params = {\n",
    "            'objective': 'regression', 'metric': 'rmse', 'learning_rate': 0.05, 'num_leaves': 31,\n",
    "            'max_depth': 8, 'min_child_samples': 10, 'feature_fraction': 0.8, 'verbose': -1\n",
    "        }\n",
    "        dtr = lgb.Dataset(Xn, label=yn)\n",
    "        if len(Xvn) > 0:\n",
    "            dva = lgb.Dataset(Xvn, label=yvn)\n",
    "            models['normal'] = lgb.train(params, dtr, valid_sets=[dva],\n",
    "                                         num_boost_round=1000,\n",
    "                                         callbacks=[lgb.early_stopping(stopping_rounds=30)])\n",
    "        else:\n",
    "            models['normal'] = lgb.train(params, dtr, num_boost_round=1000)\n",
    "    return models\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f38f2f9",
   "metadata": {},
   "source": [
    "## Data loading (MySQL with CSV fallback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dfe99667",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def load_dataset() -> pd.DataFrame:\n",
    "    \"\"\"Try MySQL first; fallback to CSV via LOGISTICS_CSV_PATH; else raise.\"\"\"\n",
    "    # MySQL\n",
    "    try:\n",
    "        engine = create_engine(\n",
    "            f\"mysql+mysqlconnector://{os.getenv('MYSQL_USER','root')}:{os.getenv('MYSQL_PASSWORD','password')}\"\n",
    "            f\"@{os.getenv('MYSQL_HOST','localhost')}:{os.getenv('MYSQL_PORT','3306')}/{os.getenv('MYSQL_DB','sys')}\"\n",
    "        )\n",
    "        df = pd.read_sql(\"SELECT * FROM us_logistics;\", engine)\n",
    "        if not df.empty:\n",
    "            logger.info(\"Loaded %s rows from MySQL us_logistics\", len(df))\n",
    "            return df\n",
    "    except Exception as e:\n",
    "        logger.warning(\"MySQL read failed: %s\", e)\n",
    "    # CSV\n",
    "    path = os.getenv(\"LOGISTICS_CSV_PATH\", \"logistics_shipments_dataset.csv\")\n",
    "    if os.path.exists(path):\n",
    "        df = pd.read_csv(path)\n",
    "        logger.info(\"Loaded %s rows from CSV %s\", len(df), path)\n",
    "        return df\n",
    "    raise RuntimeError(\"Could not load data from MySQL or CSV. Set DB env vars or LOGISTICS_CSV_PATH.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90bf2846",
   "metadata": {},
   "source": [
    "## Main training pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "af9632b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def main():\n",
    "    try:\n",
    "        logger.info(\"=== START TRAINING PIPELINE ===\")\n",
    "        df = load_dataset()\n",
    "\n",
    "        # Basic standardization\n",
    "        df = handle_missing_data_smart(df)\n",
    "        # Global IQR trim for Cost\n",
    "        if \"Cost\" in df.columns:\n",
    "            Q1 = df[\"Cost\"].quantile(0.25); Q3 = df[\"Cost\"].quantile(0.75); IQR = Q3 - Q1\n",
    "            lb, ub = Q1 - 1.5 * IQR, Q3 + 1.5 * IQR\n",
    "            before = len(df)\n",
    "            df = df[(df[\"Cost\"] >= lb) & (df[\"Cost\"] <= ub)]\n",
    "            logger.info(\"Removed %d global cost outliers\", before - len(df))\n",
    "\n",
    "        df = detect_and_handle_dhl_outliers(df)\n",
    "        df = feature_engineering(df)\n",
    "        df = enhanced_dhl_features(df)\n",
    "        df = enhanced_dhl_distance_features(df)\n",
    "        df = enhanced_dhl_weight_features(df)\n",
    "        df = add_problem_route_features(df)\n",
    "        df = enhanced_days_features(df)\n",
    "\n",
    "        df['Cost_log'] = np.log1p(df['Cost'])\n",
    "\n",
    "        # Split\n",
    "        carrier_counts = df['Carrier'].value_counts()\n",
    "        stratify_col = df['Carrier'] if (len(carrier_counts) > 1 and carrier_counts.min() > 1) else None\n",
    "\n",
    "        base_num_cols = [\n",
    "            'Distance_miles','Weight_kg','month','day_of_week','day_of_month',\n",
    "            'is_weekend','is_holiday_season',\n",
    "            'is_dhl','is_usps','is_ups','is_fedex',\n",
    "            'dhl_distance','usps_distance','dhl_weight','usps_weight',\n",
    "            'is_problem_route','is_long_distance_dhl','dhl_long_distance','problem_route_distance',\n",
    "            'dhl_distance_tier','dhl_weight_tier','dhl_weekend','dhl_holiday',\n",
    "            'dhl_distance_tier_detailed','dhl_very_long_distance','dhl_distance_squared',\n",
    "            'dhl_weight_tier_detailed','dhl_heavy_package','dhl_very_heavy_package','dhl_weight_distance'\n",
    "        ]\n",
    "        base_num_cols = [c for c in base_num_cols if c in df.columns]\n",
    "        cat_cols_no_route = [c for c in ['Carrier','origin_warehouse','Destination'] if c in df.columns]\n",
    "\n",
    "        cols_for_split = ['Carrier','origin_warehouse','Destination','route'] + base_num_cols + ['Cost_log']\n",
    "        if 'Transit_Days' in df.columns: cols_for_split.append('Transit_Days')\n",
    "        cols_for_split = list(dict.fromkeys([c for c in cols_for_split if c in df.columns]))\n",
    "\n",
    "        df_split = df[cols_for_split].copy()\n",
    "        y_cost = df_split['Cost_log']\n",
    "        y_days = df_split['Transit_Days'] if 'Transit_Days' in df_split.columns else pd.Series(0, index=df_split.index)\n",
    "\n",
    "        X_train, X_val, y_cost_train, y_cost_val, y_days_train, y_days_val = train_test_split(\n",
    "            df_split.drop(columns=['Cost_log','Transit_Days'], errors='ignore'),\n",
    "            y_cost, y_days, test_size=0.2, random_state=42, stratify=stratify_col\n",
    "        )\n",
    "        df_train = df.loc[X_train.index].copy()\n",
    "        df_val = df.loc[X_val.index].copy()\n",
    "\n",
    "        # Post-split aggregates (train-only)\n",
    "        cr_counts = df_train.groupby(['Carrier','route'], observed=False).size().rename('carrier_route_count')\n",
    "        def add_train_only_counts(dframe):\n",
    "            idx = dframe.set_index(['Carrier','route']).index\n",
    "            vals = idx.map(cr_counts).astype('float').fillna(0.0).values\n",
    "            return vals\n",
    "        X_train['carrier_route_count'] = add_train_only_counts(X_train)\n",
    "        X_val['carrier_route_count'] = add_train_only_counts(X_val)\n",
    "\n",
    "        def add_days_aggregates(d_target):\n",
    "            if 'Transit_Days' not in df_train.columns:\n",
    "                for c in ['carrier_avg_days','route_avg_days','carrier_route_avg_days']:\n",
    "                    d_target[c] = 0.0\n",
    "                return d_target\n",
    "            carrier_map = df_train.groupby('Carrier', observed=False)['Transit_Days'].mean()\n",
    "            route_map = df_train.groupby('route', observed=False)['Transit_Days'].mean()\n",
    "            cr_map = df_train.groupby(['Carrier','route'], observed=False)['Transit_Days'].mean()\n",
    "            gl = df_train['Transit_Days'].mean()\n",
    "            d_target['carrier_avg_days'] = d_target['Carrier'].map(carrier_map)\n",
    "            d_target['route_avg_days'] = d_target['route'].map(route_map)\n",
    "            d_target['carrier_route_avg_days'] = d_target.set_index(['Carrier','route']).index.map(cr_map)\n",
    "            for c in ['carrier_avg_days','route_avg_days','carrier_route_avg_days']:\n",
    "                d_target[c] = d_target[c].astype('float').fillna(gl)\n",
    "            return d_target\n",
    "        X_train_days = add_days_aggregates(X_train.copy())\n",
    "        X_val_days = add_days_aggregates(X_val.copy())\n",
    "\n",
    "        analyze_dhl_data_quality(df)\n",
    "\n",
    "        # Preprocessors\n",
    "        num_cols_cost = base_num_cols + ['carrier_route_count']\n",
    "        cat_cols_cost = cat_cols_no_route\n",
    "        num_cols_days = base_num_cols + ['carrier_route_count','carrier_avg_days','route_avg_days','carrier_route_avg_days']\n",
    "        cat_cols_days = cat_cols_no_route\n",
    "\n",
    "        num_pipe = Pipeline([('imputer', SimpleImputer(strategy='median')), ('scaler', StandardScaler())])\n",
    "        cat_pipe = Pipeline([('imputer', SimpleImputer(strategy='constant', fill_value='Unknown')), ('onehot', make_ohe())])\n",
    "\n",
    "        preprocessor_cost = ColumnTransformer(\n",
    "            transformers=[\n",
    "                ('num', num_pipe, num_cols_cost),\n",
    "                ('cat', cat_pipe, cat_cols_cost),\n",
    "                ('route_hash', RouteHashingEncoder(n_features=256), ['route'])\n",
    "            ], remainder='drop'\n",
    "        )\n",
    "        preprocessor_days = ColumnTransformer(\n",
    "            transformers=[\n",
    "                ('num', Pipeline([('imputer', SimpleImputer(strategy='median')), ('scaler', StandardScaler())]), num_cols_days),\n",
    "                ('cat', Pipeline([('imputer', SimpleImputer(strategy='constant', fill_value='Unknown')), ('onehot', make_ohe())]), cat_cols_days),\n",
    "                ('route_hash', RouteHashingEncoder(n_features=256), ['route'])\n",
    "            ], remainder='drop'\n",
    "        )\n",
    "\n",
    "        # Dtypes\n",
    "        for dfX in (X_train, X_val, X_train_days, X_val_days):\n",
    "            for c in ['Distance_miles','Weight_kg']:\n",
    "                if c in dfX.columns: dfX[c] = dfX[c].astype('float')\n",
    "            for c in cat_cols_no_route + ['route']:\n",
    "                if c in dfX.columns: dfX[c] = dfX[c].fillna(\"Unknown\").astype(str)\n",
    "\n",
    "        # Fit/transform\n",
    "        X_train_pre_cost = preprocessor_cost.fit_transform(X_train)\n",
    "        X_val_pre_cost = preprocessor_cost.transform(X_val)\n",
    "        X_train_pre_days = preprocessor_days.fit_transform(X_train_days)\n",
    "        X_val_pre_days = preprocessor_days.transform(X_val_days)\n",
    "\n",
    "        # Numpy\n",
    "        Xtr_c = X_train_pre_cost if isinstance(X_train_pre_cost, np.ndarray) else X_train_pre_cost.toarray() if hasattr(X_train_pre_cost, \"toarray\") else X_train_pre_cost\n",
    "        Xva_c = X_val_pre_cost if isinstance(X_val_pre_cost, np.ndarray) else X_val_pre_cost.toarray() if hasattr(X_val_pre_cost, \"toarray\") else X_val_pre_cost\n",
    "        ytr_c = y_cost_train.values if hasattr(y_cost_train,'values') else y_cost_train\n",
    "        yva_c = y_cost_val.values if hasattr(y_cost_val,'values') else y_cost_val\n",
    "\n",
    "        Xtr_d = X_train_pre_days if isinstance(X_train_pre_days, np.ndarray) else X_train_pre_days.toarray() if hasattr(X_train_pre_days, \"toarray\") else X_train_pre_days\n",
    "        Xva_d = X_val_pre_days if isinstance(X_val_pre_days, np.ndarray) else X_val_pre_days.toarray() if hasattr(X_val_pre_days, \"toarray\") else X_val_pre_days\n",
    "        ytr_d = y_days_train.values if hasattr(y_days_train,'values') else y_days_train\n",
    "        yva_d = y_days_val.values if hasattr(y_days_val,'values') else y_days_val\n",
    "\n",
    "        # Optuna tuning\n",
    "        def get_common_params(trial):\n",
    "            return {\n",
    "                'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.2, log=True),\n",
    "                'num_leaves': trial.suggest_int('num_leaves', 20, 200),\n",
    "                'max_depth': trial.suggest_int('max_depth', 5, 20),\n",
    "                'min_child_samples': trial.suggest_int('min_child_samples', 5, 50),\n",
    "                'feature_fraction': trial.suggest_float('feature_fraction', 0.6, 1.0),\n",
    "                'bagging_fraction': trial.suggest_float('bagging_fraction', 0.6, 1.0),\n",
    "                'bagging_freq': trial.suggest_int('bagging_freq', 1, 10),\n",
    "                'lambda_l1': trial.suggest_float('lambda_l1', 1e-8, 10.0, log=True),\n",
    "                'lambda_l2': trial.suggest_float('lambda_l2', 1e-8, 10.0, log=True),\n",
    "            }\n",
    "        def objective_cost(trial):\n",
    "            params = get_common_params(trial)\n",
    "            params.update({'objective':'regression','metric':'rmse','verbose':-1,'random_state':42})\n",
    "            dtr = lgb.Dataset(Xtr_c, label=ytr_c); dva = lgb.Dataset(Xva_c, label=yva_c)\n",
    "            mdl = lgb.train(params, dtr, valid_sets=[dva], num_boost_round=1000,\n",
    "                            callbacks=[lgb.log_evaluation(0), lgb.early_stopping(stopping_rounds=50)])\n",
    "            yhat = np.expm1(mdl.predict(Xva_c, num_iteration=getattr(mdl,\"best_iteration\",None)))\n",
    "            rmse = np.sqrt(mean_squared_error(np.expm1(yva_c), yhat))\n",
    "            return rmse\n",
    "        def objective_days(trial):\n",
    "            params = get_common_params(trial)\n",
    "            params.update({'objective':'poisson','metric':'rmse','verbose':-1,'random_state':42})\n",
    "            dtr = lgb.Dataset(Xtr_d, label=ytr_d); dva = lgb.Dataset(Xva_d, label=yva_d)\n",
    "            mdl = lgb.train(params, dtr, valid_sets=[dva], num_boost_round=1000,\n",
    "                            callbacks=[lgb.log_evaluation(0), lgb.early_stopping(stopping_rounds=50)])\n",
    "            yhat = mdl.predict(Xva_d, num_iteration=getattr(mdl,\"best_iteration\",None))\n",
    "            rmse = np.sqrt(mean_squared_error(yva_d, yhat))\n",
    "            return rmse\n",
    "\n",
    "        logger.info(\"Tuning with Optuna\")\n",
    "        study_cost = optuna.create_study(direction=\"minimize\", sampler=optuna.samplers.TPESampler(seed=42))\n",
    "        study_cost.optimize(objective_cost, n_trials=30, show_progress_bar=False)\n",
    "        study_days = optuna.create_study(direction=\"minimize\", sampler=optuna.samplers.TPESampler(seed=42))\n",
    "        study_days.optimize(objective_days, n_trials=30, show_progress_bar=False)\n",
    "        logger.info(\"Best RMSE (cost)=%.4f | (days)=%.4f\", study_cost.best_value, study_days.best_value)\n",
    "\n",
    "        best_params_cost = {**study_cost.best_params, 'objective':'regression','metric':'rmse','verbose':-1,'random_state':42}\n",
    "        best_params_days = {**study_days.best_params, 'objective':'poisson','metric':'rmse','verbose':-1,'random_state':42}\n",
    "\n",
    "        # Final global models\n",
    "        mdl_cost = lgb.train(best_params_cost, lgb.Dataset(Xtr_c, label=ytr_c),\n",
    "                             valid_sets=[lgb.Dataset(Xva_c, label=yva_c)],\n",
    "                             num_boost_round=1000, callbacks=[lgb.log_evaluation(100), lgb.early_stopping(stopping_rounds=50)])\n",
    "        mdl_days = lgb.train(best_params_days, lgb.Dataset(Xtr_d, label=ytr_d),\n",
    "                             valid_sets=[lgb.Dataset(Xva_d, label=yva_d)],\n",
    "                             num_boost_round=1000, callbacks=[lgb.log_evaluation(100), lgb.early_stopping(stopping_rounds=50)])\n",
    "\n",
    "        # Carrier-specific cost models\n",
    "        logger.info(\"Training carrier-specific models\")\n",
    "        cost_models = train_carrier_specific_models(Xtr_c, ytr_c, Xva_c, yva_c, df_train, df_val, 'cost')\n",
    "\n",
    "        # Calibration\n",
    "        logger.info(\"Calculating calibration factors\")\n",
    "        val_cost_raw = mdl_cost.predict(Xva_c, num_iteration=getattr(mdl_cost,\"best_iteration\",None))\n",
    "        val_cost_exp = np.expm1(val_cost_raw)\n",
    "        cost_cal = calculate_dynamic_calibration(df_val, np.expm1(yva_c), val_cost_exp, 'cost')\n",
    "        val_days = mdl_days.predict(Xva_d, num_iteration=getattr(mdl_days,\"best_iteration\",None))\n",
    "        days_cal = calculate_dynamic_calibration(df_val, yva_d, val_days, 'days')\n",
    "\n",
    "        # Error analysis\n",
    "        analyze_dhl_errors(df_val, np.expm1(yva_c), val_cost_exp, 'cost')\n",
    "\n",
    "        # Adaptive weights (for eval/reporting)\n",
    "        global_val = np.expm1(mdl_cost.predict(Xva_c, num_iteration=getattr(mdl_cost,\"best_iteration\",None)))\n",
    "        carrier_val = predict_with_carrier_specific_models(cost_models, Xva_c, df_val, 'cost')\n",
    "        carrier_val = np.where(carrier_val == 0, global_val, carrier_val)\n",
    "        adaptive_w = compute_adaptive_weights(global_val, carrier_val, y_cost_val, df_val)\n",
    "\n",
    "        # CV\n",
    "        cv_cost = cv_lightgbm(Xtr_c, ytr_c, best_params_cost, 'rmse_expm1', cv=5)\n",
    "        cv_days = cv_lightgbm(Xtr_d, ytr_d, best_params_days, 'rmse', cv=5)\n",
    "        logger.info(\"CV RMSE Cost: %.4f ± %.4f | Days: %.4f ± %.4f\", cv_cost.mean(), cv_cost.std(), cv_days.mean(), cv_days.std())\n",
    "\n",
    "        # Per-carrier evaluation\n",
    "        def evaluate_per_carrier(Xc, Xd, ylog, ydays, meta_df, mdl_c, mdl_d, group_models, cal_cost, cal_days, w_adapt):\n",
    "            carriers = sorted(meta_df['Carrier'].dropna().unique())\n",
    "            cost_global = apply_calibrated_predictions(mdl_c, Xc, meta_df, 'cost', cal_cost)\n",
    "            days_global = apply_calibrated_predictions(mdl_d, Xd, meta_df, 'days', cal_days)\n",
    "            # adaptive blend\n",
    "            cost_adapt = np.zeros(len(meta_df))\n",
    "            gpred = np.expm1(mdl_c.predict(Xc, num_iteration=getattr(mdl_c,\"best_iteration\",None)))\n",
    "            cpred = predict_with_carrier_specific_models(group_models, Xc, meta_df, 'cost')\n",
    "            for i, car in enumerate(meta_df['Carrier'].values):\n",
    "                if car == 'DHL' and any(k.startswith('dhl_') for k in group_models.keys()):\n",
    "                    cost_adapt[i] = cpred[i]\n",
    "                else:\n",
    "                    w = w_adapt.get(car, 0.5)\n",
    "                    c = cpred[i] if cpred[i] != 0 else gpred[i]\n",
    "                    cost_adapt[i] = w * gpred[i] + (1 - w) * c\n",
    "            rows = []\n",
    "            for car in carriers:\n",
    "                m = (meta_df['Carrier'].values == car)\n",
    "                if not np.any(m): continue\n",
    "                rmse_cg = float(np.sqrt(mean_squared_error(np.expm1(ylog.values[m]), cost_global[m])))\n",
    "                rmse_ca = float(np.sqrt(mean_squared_error(np.expm1(ylog.values[m]), cost_adapt[m])))\n",
    "                rmse_d  = float(np.sqrt(mean_squared_error(ydays.values[m], days_global[m])))\n",
    "                rows.append({\"Carrier\":car,\"Samples\":int(m.sum()),\n",
    "                             \"RMSE_Cost_Calibrated\":rmse_cg,\n",
    "                             \"RMSE_Cost_Adaptive\":rmse_ca,\n",
    "                             \"RMSE_Transit_Days\":rmse_d})\n",
    "            return pd.DataFrame(rows)\n",
    "\n",
    "        carrier_rmse = evaluate_per_carrier(\n",
    "            Xva_c, Xva_d, y_cost_val, y_days_val, df_val,\n",
    "            mdl_cost, mdl_days, cost_models, cost_cal, days_cal, adaptive_w\n",
    "        )\n",
    "\n",
    "        # Save artifacts\n",
    "        out = \"model_artifacts\"; os.makedirs(out, exist_ok=True)\n",
    "        joblib.dump(mdl_cost, os.path.join(out, \"cost_model.pkl\"))\n",
    "        joblib.dump(mdl_days, os.path.join(out, \"transit_days_model.pkl\"))\n",
    "        joblib.dump(preprocessor_cost, os.path.join(out, \"preprocessor_cost.pkl\"))\n",
    "        joblib.dump(preprocessor_days, os.path.join(out, \"preprocessor_days.pkl\"))\n",
    "        joblib.dump(cost_models, os.path.join(out, \"cost_models_grouped.pkl\"))\n",
    "        # Generic names for Streamlit sidebar\n",
    "        joblib.dump(preprocessor_cost, os.path.join(out, \"preprocessor.pkl\"))\n",
    "        joblib.dump(mdl_cost, os.path.join(out, \"cost_model.pkl\"))\n",
    "\n",
    "        # best_params.json (features + calibration + metrics)\n",
    "        best = {\n",
    "            \"cost_params\": best_params_cost,\n",
    "            \"days_params\": best_params_days,\n",
    "            \"cost_features\": {\"numerical\": list(num_cols_cost), \"categorical\": list(cat_cols_cost), \"route_hash_features\": 256},\n",
    "            \"days_features\": {\"numerical\": list(num_cols_days), \"categorical\": list(cat_cols_days), \"route_hash_features\": 256},\n",
    "            \"cv_scores\": {\"cost_mean\": float(cv_cost.mean()), \"cost_std\": float(cv_cost.std()),\n",
    "                          \"days_mean\": float(cv_days.mean()), \"days_std\": float(cv_days.std())},\n",
    "            \"calibration\": {\"cost\": cost_cal, \"days\": days_cal}\n",
    "        }\n",
    "        # validation RMSE summary\n",
    "        cost_val_cal = apply_calibrated_predictions(mdl_cost, Xva_c, df_val, 'cost', cost_cal)\n",
    "        cost_val_adapt = np.zeros(len(df_val))\n",
    "        gpred = np.expm1(mdl_cost.predict(Xva_c, num_iteration=getattr(mdl_cost,\"best_iteration\",None)))\n",
    "        cpred = predict_with_carrier_specific_models(cost_models, Xva_c, df_val, 'cost')\n",
    "        for i, car in enumerate(df_val['Carrier'].values):\n",
    "            if car == 'DHL' and any(k.startswith('dhl_') for k in cost_models.keys()):\n",
    "                cost_val_adapt[i] = cpred[i]\n",
    "            else:\n",
    "                w = adaptive_w.get(car, 0.5)\n",
    "                c = cpred[i] if cpred[i] != 0 else gpred[i]\n",
    "                cost_val_adapt[i] = w * gpred[i] + (1 - w) * c\n",
    "        rmse_cost_cal = float(np.sqrt(mean_squared_error(np.expm1(yva_c), cost_val_cal)))\n",
    "        rmse_cost_adp = float(np.sqrt(mean_squared_error(np.expm1(yva_c), cost_val_adapt)))\n",
    "        days_val_cal = apply_calibrated_predictions(mdl_days, Xva_d, df_val, 'days', days_cal)\n",
    "        rmse_days_cal = float(np.sqrt(mean_squared_error(yva_d, days_val_cal)))\n",
    "        best[\"validation_rmse\"] = {\"cost_calibrated\": rmse_cost_cal, \"cost_adaptive\": rmse_cost_adp, \"days_calibrated\": rmse_days_cal}\n",
    "\n",
    "        with open(os.path.join(out, \"best_params.json\"), \"w\") as f:\n",
    "            json.dump(best, f, indent=2)\n",
    "\n",
    "        carrier_rmse.to_csv(os.path.join(out, \"carrier_performance.csv\"), index=False)\n",
    "        plot_carrier_rmse(carrier_rmse, out)\n",
    "\n",
    "        logger.info(\"Artifacts saved to %s\", out)\n",
    "        logger.info(\"=== TRAINING COMPLETED SUCCESSFULLY ===\")\n",
    "\n",
    "        return {\n",
    "            \"artifacts_dir\": out,\n",
    "            \"best_params_json\": os.path.join(out, \"best_params.json\"),\n",
    "            \"carrier_performance_csv\": os.path.join(out, \"carrier_performance.csv\"),\n",
    "            \"rmse_plot_png\": os.path.join(out, \"carrier_rmse_analysis.png\"),\n",
    "            \"when\": datetime.now(UTC).isoformat().replace(\"+00:00\", \"Z\")\n",
    "        }\n",
    "\n",
    "    except Exception as e:\n",
    "        logger.exception(\"Error during pipeline execution\")\n",
    "        raise\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "922a1169",
   "metadata": {},
   "source": [
    "## Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c85f2f72",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-07 19:18:06,290 - INFO - === START TRAINING PIPELINE ===\n",
      "2025-09-07 19:18:06,328 - INFO - Loaded 2000 rows from MySQL us_logistics\n",
      "2025-09-07 19:18:06,331 - INFO - Removed 41 rows with missing Cost\n",
      "2025-09-07 19:18:06,335 - INFO - Removed 4 global cost outliers\n",
      "2025-09-07 19:18:06,361 - INFO - DHL samples: 275\n",
      "2025-09-07 19:18:06,362 - INFO - Missing Distance_miles: 0 (0.0%)\n",
      "2025-09-07 19:18:06,362 - INFO - Missing Weight_kg: 0 (0.0%)\n",
      "2025-09-07 19:18:06,362 - INFO - Missing origin_warehouse: 0 (0.0%)\n",
      "2025-09-07 19:18:06,363 - INFO - Missing Destination: 0 (0.0%)\n",
      "2025-09-07 19:18:06,363 - INFO - Distance 105-2499 | Weight 3.1-88.7 | Cost 32-464\n",
      "2025-09-07 19:18:06,388 - INFO - Tuning with Optuna\n",
      "[I 2025-09-07 19:18:06,388] A new study created in memory with name: no-name-aefcb138-dfd1-49b8-ba1b-fdfbbc03da8b\n",
      "[I 2025-09-07 19:18:06,506] Trial 0 finished with value: 25.0287761646713 and parameters: {'learning_rate': 0.030710573677773714, 'num_leaves': 192, 'max_depth': 16, 'min_child_samples': 32, 'feature_fraction': 0.6624074561769746, 'bagging_fraction': 0.662397808134481, 'bagging_freq': 1, 'lambda_l1': 0.6245760287469887, 'lambda_l2': 0.002570603566117596}. Best is trial 0 with value: 25.0287761646713.\n",
      "[I 2025-09-07 19:18:06,573] Trial 1 finished with value: 24.65484374287327 and parameters: {'learning_rate': 0.08341106432362087, 'num_leaves': 23, 'max_depth': 20, 'min_child_samples': 43, 'feature_fraction': 0.6849356442713105, 'bagging_fraction': 0.6727299868828402, 'bagging_freq': 2, 'lambda_l1': 5.472429642032189e-06, 'lambda_l2': 0.00052821153945323}. Best is trial 1 with value: 24.65484374287327.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[357]\tvalid_0's rmse: 0.153029\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[116]\tvalid_0's rmse: 0.152512\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-07 19:18:06,767] Trial 2 finished with value: 27.980994137976317 and parameters: {'learning_rate': 0.03647316284911211, 'num_leaves': 72, 'max_depth': 14, 'min_child_samples': 11, 'feature_fraction': 0.7168578594140872, 'bagging_fraction': 0.7465447373174766, 'bagging_freq': 5, 'lambda_l1': 0.11656915613247415, 'lambda_l2': 6.267062696005991e-07}. Best is trial 1 with value: 24.65484374287327.\n",
      "[I 2025-09-07 19:18:06,847] Trial 3 finished with value: 24.287135410013047 and parameters: {'learning_rate': 0.04666963767236924, 'num_leaves': 127, 'max_depth': 5, 'min_child_samples': 32, 'feature_fraction': 0.6682096494749166, 'bagging_fraction': 0.6260206371941118, 'bagging_freq': 10, 'lambda_l1': 4.905556676028766, 'lambda_l2': 0.1886149587855396}. Best is trial 3 with value: 24.287135410013047.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[212]\tvalid_0's rmse: 0.161937\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[636]\tvalid_0's rmse: 0.155349\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-07 19:18:06,988] Trial 4 finished with value: 24.36299639937509 and parameters: {'learning_rate': 0.02490643969382439, 'num_leaves': 37, 'max_depth': 15, 'min_child_samples': 25, 'feature_fraction': 0.6488152939379115, 'bagging_fraction': 0.798070764044508, 'bagging_freq': 1, 'lambda_l1': 1.5271567592511939, 'lambda_l2': 2.133142332373e-06}. Best is trial 3 with value: 24.287135410013047.\n",
      "[I 2025-09-07 19:18:07,039] Trial 5 finished with value: 23.611632998211867 and parameters: {'learning_rate': 0.07277150634170934, 'num_leaves': 76, 'max_depth': 13, 'min_child_samples': 30, 'feature_fraction': 0.6739417822102108, 'bagging_fraction': 0.9878338511058234, 'bagging_freq': 8, 'lambda_l1': 2.8542399074977594, 'lambda_l2': 1.1309571585271492}. Best is trial 5 with value: 23.611632998211867.\n",
      "[I 2025-09-07 19:18:07,123] Trial 6 finished with value: 25.567581223641096 and parameters: {'learning_rate': 0.059963338824126605, 'num_leaves': 186, 'max_depth': 6, 'min_child_samples': 14, 'feature_fraction': 0.6180909155642152, 'bagging_fraction': 0.7301321323053057, 'bagging_freq': 4, 'lambda_l1': 2.7678419414850017e-06, 'lambda_l2': 0.287499823474079}. Best is trial 5 with value: 23.611632998211867.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[561]\tvalid_0's rmse: 0.151568\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[225]\tvalid_0's rmse: 0.148528\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[173]\tvalid_0's rmse: 0.15158\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-07 19:18:07,263] Trial 7 finished with value: 25.294221663461528 and parameters: {'learning_rate': 0.02911701023242742, 'num_leaves': 70, 'max_depth': 13, 'min_child_samples': 11, 'feature_fraction': 0.9208787923016158, 'bagging_fraction': 0.6298202574719083, 'bagging_freq': 10, 'lambda_l1': 0.08916674715636552, 'lambda_l2': 6.143857495033091e-07}. Best is trial 5 with value: 23.611632998211867.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[169]\tvalid_0's rmse: 0.151191\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-07 19:18:07,557] Trial 8 finished with value: 23.62095468745595 and parameters: {'learning_rate': 0.010166803740022877, 'num_leaves': 167, 'max_depth': 16, 'min_child_samples': 38, 'feature_fraction': 0.9085081386743783, 'bagging_fraction': 0.6296178606936361, 'bagging_freq': 4, 'lambda_l1': 1.1036250149900698e-07, 'lambda_l2': 0.5860448217200526}. Best is trial 5 with value: 23.611632998211867.\n",
      "[I 2025-09-07 19:18:07,625] Trial 9 finished with value: 25.438641989404033 and parameters: {'learning_rate': 0.06470376604234768, 'num_leaves': 79, 'max_depth': 6, 'min_child_samples': 19, 'feature_fraction': 0.7300733288106988, 'bagging_fraction': 0.8918424713352257, 'bagging_freq': 7, 'lambda_l1': 0.9658611176861261, 'lambda_l2': 0.0001778010520878397}. Best is trial 5 with value: 23.611632998211867.\n",
      "[I 2025-09-07 19:18:07,686] Trial 10 finished with value: 26.05346027521042 and parameters: {'learning_rate': 0.1788820497328707, 'num_leaves': 124, 'max_depth': 10, 'min_child_samples': 47, 'feature_fraction': 0.811268713696243, 'bagging_fraction': 0.9630659181130072, 'bagging_freq': 8, 'lambda_l1': 0.002861549446231718, 'lambda_l2': 5.358757267475057}. Best is trial 5 with value: 23.611632998211867.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[676]\tvalid_0's rmse: 0.149095\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[152]\tvalid_0's rmse: 0.154431\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[78]\tvalid_0's rmse: 0.157359\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[750]\tvalid_0's rmse: 0.150343\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-07 19:18:09,252] Trial 11 finished with value: 24.538018712983295 and parameters: {'learning_rate': 0.010205410978180531, 'num_leaves': 157, 'max_depth': 18, 'min_child_samples': 39, 'feature_fraction': 0.95621601194762, 'bagging_fraction': 0.9976023763984891, 'bagging_freq': 7, 'lambda_l1': 4.694221200463742e-08, 'lambda_l2': 9.604469751203892}. Best is trial 5 with value: 23.611632998211867.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-07 19:18:09,582] Trial 12 finished with value: 23.860262326441315 and parameters: {'learning_rate': 0.010486647476761056, 'num_leaves': 155, 'max_depth': 10, 'min_child_samples': 36, 'feature_fraction': 0.8624306017432583, 'bagging_fraction': 0.8925233663655074, 'bagging_freq': 4, 'lambda_l1': 0.00042371132433695466, 'lambda_l2': 0.0491451363965605}. Best is trial 5 with value: 23.611632998211867.\n",
      "[I 2025-09-07 19:18:09,657] Trial 13 finished with value: 25.55403540893171 and parameters: {'learning_rate': 0.13379889603180217, 'num_leaves': 94, 'max_depth': 11, 'min_child_samples': 25, 'feature_fraction': 0.8158535596006177, 'bagging_fraction': 0.8873249911216153, 'bagging_freq': 8, 'lambda_l1': 1.3000481036980694e-07, 'lambda_l2': 0.014775475739688154}. Best is trial 5 with value: 23.611632998211867.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[604]\tvalid_0's rmse: 0.148845\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[83]\tvalid_0's rmse: 0.151238\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-07 19:18:09,868] Trial 14 finished with value: 23.377908989710406 and parameters: {'learning_rate': 0.016030182697577208, 'num_leaves': 157, 'max_depth': 17, 'min_child_samples': 50, 'feature_fraction': 0.9994891134515507, 'bagging_fraction': 0.8147657261706673, 'bagging_freq': 6, 'lambda_l1': 8.135462362525248e-06, 'lambda_l2': 3.693544333296998e-05}. Best is trial 14 with value: 23.377908989710406.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[492]\tvalid_0's rmse: 0.147902\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-07 19:18:10,509] Trial 15 finished with value: 28.65486358384242 and parameters: {'learning_rate': 0.015916913630789346, 'num_leaves': 122, 'max_depth': 20, 'min_child_samples': 5, 'feature_fraction': 0.7531177448189, 'bagging_fraction': 0.8346098620430572, 'bagging_freq': 6, 'lambda_l1': 5.704246908471008e-06, 'lambda_l2': 2.735063947885515e-05}. Best is trial 14 with value: 23.377908989710406.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[360]\tvalid_0's rmse: 0.165862\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-07 19:18:10,753] Trial 16 finished with value: 24.405008014758035 and parameters: {'learning_rate': 0.018923194380010718, 'num_leaves': 46, 'max_depth': 18, 'min_child_samples': 50, 'feature_fraction': 0.7766748795291956, 'bagging_fraction': 0.9438599500782207, 'bagging_freq': 9, 'lambda_l1': 0.0029472905339895214, 'lambda_l2': 1.314053143275926e-08}. Best is trial 14 with value: 23.377908989710406.\n",
      "[I 2025-09-07 19:18:10,819] Trial 17 finished with value: 25.239182561023025 and parameters: {'learning_rate': 0.10974601331685604, 'num_leaves': 99, 'max_depth': 12, 'min_child_samples': 44, 'feature_fraction': 0.8514142443596113, 'bagging_fraction': 0.8264255180564114, 'bagging_freq': 6, 'lambda_l1': 0.00011809048384728257, 'lambda_l2': 2.9213259776727324e-05}. Best is trial 14 with value: 23.377908989710406.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[494]\tvalid_0's rmse: 0.151603\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[89]\tvalid_0's rmse: 0.154652\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-07 19:18:10,935] Trial 18 finished with value: 25.423095627103727 and parameters: {'learning_rate': 0.04873514165664674, 'num_leaves': 140, 'max_depth': 8, 'min_child_samples': 21, 'feature_fraction': 0.6079503762500515, 'bagging_fraction': 0.76500726490148, 'bagging_freq': 8, 'lambda_l1': 9.514769556766346e-05, 'lambda_l2': 0.005914969601806861}. Best is trial 14 with value: 23.377908989710406.\n",
      "[I 2025-09-07 19:18:11,103] Trial 19 finished with value: 23.5200076730802 and parameters: {'learning_rate': 0.018453207518929104, 'num_leaves': 53, 'max_depth': 18, 'min_child_samples': 31, 'feature_fraction': 0.9916975183348293, 'bagging_fraction': 0.9347949395453552, 'bagging_freq': 5, 'lambda_l1': 0.017847429374350895, 'lambda_l2': 2.455918006464903e-08}. Best is trial 14 with value: 23.377908989710406.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[201]\tvalid_0's rmse: 0.152956\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[240]\tvalid_0's rmse: 0.146355\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-07 19:18:11,353] Trial 20 finished with value: 23.766047611280367 and parameters: {'learning_rate': 0.015258279902564394, 'num_leaves': 58, 'max_depth': 18, 'min_child_samples': 43, 'feature_fraction': 0.999271196853437, 'bagging_fraction': 0.9354348266823663, 'bagging_freq': 3, 'lambda_l1': 0.008225723319543179, 'lambda_l2': 1.4301670465475771e-08}. Best is trial 14 with value: 23.377908989710406.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[429]\tvalid_0's rmse: 0.147651\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-07 19:18:11,541] Trial 21 finished with value: 24.098554943375305 and parameters: {'learning_rate': 0.02108068073497902, 'num_leaves': 92, 'max_depth': 17, 'min_child_samples': 31, 'feature_fraction': 0.997710605633679, 'bagging_fraction': 0.9927091738714885, 'bagging_freq': 5, 'lambda_l1': 0.03226296274236699, 'lambda_l2': 8.160822218983402e-08}. Best is trial 14 with value: 23.377908989710406.\n",
      "[I 2025-09-07 19:18:11,689] Trial 22 finished with value: 26.089117676112654 and parameters: {'learning_rate': 0.01349853647886122, 'num_leaves': 55, 'max_depth': 14, 'min_child_samples': 28, 'feature_fraction': 0.9363330586447146, 'bagging_fraction': 0.9209533914828585, 'bagging_freq': 7, 'lambda_l1': 9.489175007246143, 'lambda_l2': 7.929091668734159e-06}. Best is trial 14 with value: 23.377908989710406.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[255]\tvalid_0's rmse: 0.146775\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[883]\tvalid_0's rmse: 0.161611\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-07 19:18:11,772] Trial 23 finished with value: 25.144890706399554 and parameters: {'learning_rate': 0.08433216983182996, 'num_leaves': 34, 'max_depth': 19, 'min_child_samples': 19, 'feature_fraction': 0.9674190575821708, 'bagging_fraction': 0.8506401207677025, 'bagging_freq': 6, 'lambda_l1': 2.0800325868110037e-05, 'lambda_l2': 0.00042525755803712}. Best is trial 14 with value: 23.377908989710406.\n",
      "[I 2025-09-07 19:18:11,935] Trial 24 finished with value: 23.873663156571027 and parameters: {'learning_rate': 0.022173167052138832, 'num_leaves': 111, 'max_depth': 16, 'min_child_samples': 34, 'feature_fraction': 0.8911804643585647, 'bagging_fraction': 0.9646998052924811, 'bagging_freq': 9, 'lambda_l1': 0.000769963237725454, 'lambda_l2': 1.4479384412941373e-07}. Best is trial 14 with value: 23.377908989710406.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[70]\tvalid_0's rmse: 0.150352\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[237]\tvalid_0's rmse: 0.148467\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-07 19:18:12,035] Trial 25 finished with value: 23.679623846092458 and parameters: {'learning_rate': 0.03900400259774833, 'num_leaves': 84, 'max_depth': 14, 'min_child_samples': 28, 'feature_fraction': 0.9700505870963768, 'bagging_fraction': 0.8691338693930994, 'bagging_freq': 5, 'lambda_l1': 3.7330168354077543e-07, 'lambda_l2': 9.57505662702554e-05}. Best is trial 14 with value: 23.377908989710406.\n",
      "[I 2025-09-07 19:18:12,143] Trial 26 finished with value: 24.79543173978767 and parameters: {'learning_rate': 0.05984352186495856, 'num_leaves': 59, 'max_depth': 17, 'min_child_samples': 40, 'feature_fraction': 0.8696418530804749, 'bagging_fraction': 0.8005534398406551, 'bagging_freq': 3, 'lambda_l1': 0.20307815632470713, 'lambda_l2': 0.0018477414658242184}. Best is trial 14 with value: 23.377908989710406.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[115]\tvalid_0's rmse: 0.146517\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[177]\tvalid_0's rmse: 0.151161\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-07 19:18:12,378] Trial 27 finished with value: 23.949026038425355 and parameters: {'learning_rate': 0.0132883491064746, 'num_leaves': 103, 'max_depth': 12, 'min_child_samples': 24, 'feature_fraction': 0.9387776292756179, 'bagging_fraction': 0.9127796583864662, 'bagging_freq': 7, 'lambda_l1': 1.2061871344139381e-08, 'lambda_l2': 4.346089928350894e-06}. Best is trial 14 with value: 23.377908989710406.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[306]\tvalid_0's rmse: 0.148674\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-07 19:18:12,649] Trial 28 finished with value: 25.256785568512736 and parameters: {'learning_rate': 0.017710191303869395, 'num_leaves': 20, 'max_depth': 15, 'min_child_samples': 48, 'feature_fraction': 0.7060183365006387, 'bagging_fraction': 0.9634700074335787, 'bagging_freq': 9, 'lambda_l1': 0.015090113643213256, 'lambda_l2': 2.0896963339390293}. Best is trial 14 with value: 23.377908989710406.\n",
      "[I 2025-09-07 19:18:12,773] Trial 29 finished with value: 24.27733404115834 and parameters: {'learning_rate': 0.029136632872615784, 'num_leaves': 196, 'max_depth': 19, 'min_child_samples': 30, 'feature_fraction': 0.8312076808522824, 'bagging_fraction': 0.6957765371853208, 'bagging_freq': 6, 'lambda_l1': 0.36186460501662293, 'lambda_l2': 0.001632914441352874}. Best is trial 14 with value: 23.377908989710406.\n",
      "[I 2025-09-07 19:18:12,774] A new study created in memory with name: no-name-af2ef94d-d9cc-4246-ade8-995adc780ac9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[596]\tvalid_0's rmse: 0.15409\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[253]\tvalid_0's rmse: 0.15005\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-07 19:18:12,838] Trial 0 finished with value: 1.4229921228863236 and parameters: {'learning_rate': 0.030710573677773714, 'num_leaves': 192, 'max_depth': 16, 'min_child_samples': 32, 'feature_fraction': 0.6624074561769746, 'bagging_fraction': 0.662397808134481, 'bagging_freq': 1, 'lambda_l1': 0.6245760287469887, 'lambda_l2': 0.002570603566117596}. Best is trial 0 with value: 1.4229921228863236.\n",
      "[I 2025-09-07 19:18:12,874] Trial 1 finished with value: 1.3784799710634779 and parameters: {'learning_rate': 0.08341106432362087, 'num_leaves': 23, 'max_depth': 20, 'min_child_samples': 43, 'feature_fraction': 0.6849356442713105, 'bagging_fraction': 0.6727299868828402, 'bagging_freq': 2, 'lambda_l1': 5.472429642032189e-06, 'lambda_l2': 0.00052821153945323}. Best is trial 1 with value: 1.3784799710634779.\n",
      "[I 2025-09-07 19:18:12,991] Trial 2 finished with value: 1.4275647385120558 and parameters: {'learning_rate': 0.03647316284911211, 'num_leaves': 72, 'max_depth': 14, 'min_child_samples': 11, 'feature_fraction': 0.7168578594140872, 'bagging_fraction': 0.7465447373174766, 'bagging_freq': 5, 'lambda_l1': 0.11656915613247415, 'lambda_l2': 6.267062696005991e-07}. Best is trial 1 with value: 1.3784799710634779.\n",
      "[I 2025-09-07 19:18:13,027] Trial 3 finished with value: 1.3802599990065167 and parameters: {'learning_rate': 0.04666963767236924, 'num_leaves': 127, 'max_depth': 5, 'min_child_samples': 32, 'feature_fraction': 0.6682096494749166, 'bagging_fraction': 0.6260206371941118, 'bagging_freq': 10, 'lambda_l1': 4.905556676028766, 'lambda_l2': 0.1886149587855396}. Best is trial 1 with value: 1.3784799710634779.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[124]\tvalid_0's rmse: 1.42299\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[40]\tvalid_0's rmse: 1.37848\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[85]\tvalid_0's rmse: 1.42756\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[88]\tvalid_0's rmse: 1.38026\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-07 19:18:13,121] Trial 4 finished with value: 1.428123607307349 and parameters: {'learning_rate': 0.02490643969382439, 'num_leaves': 37, 'max_depth': 15, 'min_child_samples': 25, 'feature_fraction': 0.6488152939379115, 'bagging_fraction': 0.798070764044508, 'bagging_freq': 1, 'lambda_l1': 1.5271567592511939, 'lambda_l2': 2.133142332373e-06}. Best is trial 1 with value: 1.3784799710634779.\n",
      "[I 2025-09-07 19:18:13,165] Trial 5 finished with value: 1.3947014225625831 and parameters: {'learning_rate': 0.07277150634170934, 'num_leaves': 76, 'max_depth': 13, 'min_child_samples': 30, 'feature_fraction': 0.6739417822102108, 'bagging_fraction': 0.9878338511058234, 'bagging_freq': 8, 'lambda_l1': 2.8542399074977594, 'lambda_l2': 1.1309571585271492}. Best is trial 1 with value: 1.3784799710634779.\n",
      "[I 2025-09-07 19:18:13,219] Trial 6 finished with value: 1.4205013521358603 and parameters: {'learning_rate': 0.059963338824126605, 'num_leaves': 186, 'max_depth': 6, 'min_child_samples': 14, 'feature_fraction': 0.6180909155642152, 'bagging_fraction': 0.7301321323053057, 'bagging_freq': 4, 'lambda_l1': 2.7678419414850017e-06, 'lambda_l2': 0.287499823474079}. Best is trial 1 with value: 1.3784799710634779.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[190]\tvalid_0's rmse: 1.42812\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[45]\tvalid_0's rmse: 1.3947\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[59]\tvalid_0's rmse: 1.4205\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-07 19:18:13,338] Trial 7 finished with value: 1.4305309807438975 and parameters: {'learning_rate': 0.02911701023242742, 'num_leaves': 70, 'max_depth': 13, 'min_child_samples': 11, 'feature_fraction': 0.9208787923016158, 'bagging_fraction': 0.6298202574719083, 'bagging_freq': 10, 'lambda_l1': 0.08916674715636552, 'lambda_l2': 6.143857495033091e-07}. Best is trial 1 with value: 1.3784799710634779.\n",
      "[I 2025-09-07 19:18:13,479] Trial 8 finished with value: 1.379062963099086 and parameters: {'learning_rate': 0.010166803740022877, 'num_leaves': 167, 'max_depth': 16, 'min_child_samples': 38, 'feature_fraction': 0.9085081386743783, 'bagging_fraction': 0.6296178606936361, 'bagging_freq': 4, 'lambda_l1': 1.1036250149900698e-07, 'lambda_l2': 0.5860448217200526}. Best is trial 1 with value: 1.3784799710634779.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[99]\tvalid_0's rmse: 1.43053\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[343]\tvalid_0's rmse: 1.37906\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[54]\tvalid_0's rmse: 1.46355\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-07 19:18:13,527] Trial 9 finished with value: 1.4635547656158727 and parameters: {'learning_rate': 0.06470376604234768, 'num_leaves': 79, 'max_depth': 6, 'min_child_samples': 19, 'feature_fraction': 0.7300733288106988, 'bagging_fraction': 0.8918424713352257, 'bagging_freq': 7, 'lambda_l1': 0.9658611176861261, 'lambda_l2': 0.0001778010520878397}. Best is trial 1 with value: 1.3784799710634779.\n",
      "[I 2025-09-07 19:18:13,566] Trial 10 finished with value: 1.4034675784988886 and parameters: {'learning_rate': 0.18168388620005324, 'num_leaves': 21, 'max_depth': 20, 'min_child_samples': 48, 'feature_fraction': 0.8182873120328862, 'bagging_fraction': 0.8760988294276582, 'bagging_freq': 3, 'lambda_l1': 4.32747580263185e-05, 'lambda_l2': 0.00020590009861590298}. Best is trial 1 with value: 1.3784799710634779.\n",
      "[I 2025-09-07 19:18:13,703] Trial 11 finished with value: 1.377435632839684 and parameters: {'learning_rate': 0.010205410978180531, 'num_leaves': 144, 'max_depth': 20, 'min_child_samples': 43, 'feature_fraction': 0.95621601194762, 'bagging_fraction': 0.6973516090536837, 'bagging_freq': 3, 'lambda_l1': 1.5161490989242467e-08, 'lambda_l2': 9.619281605720388}. Best is trial 11 with value: 1.377435632839684.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[21]\tvalid_0's rmse: 1.40347\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[314]\tvalid_0's rmse: 1.37744\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[28]\tvalid_0's rmse: 1.36576\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-07 19:18:13,742] Trial 12 finished with value: 1.3657561073579552 and parameters: {'learning_rate': 0.1286542361913006, 'num_leaves': 136, 'max_depth': 20, 'min_child_samples': 50, 'feature_fraction': 0.9978494133549762, 'bagging_fraction': 0.7097939893129923, 'bagging_freq': 2, 'lambda_l1': 2.0057322817130592e-08, 'lambda_l2': 0.01121764667975888}. Best is trial 12 with value: 1.3657561073579552.\n",
      "[I 2025-09-07 19:18:13,777] Trial 13 finished with value: 1.363110560243712 and parameters: {'learning_rate': 0.19762750325534995, 'num_leaves': 137, 'max_depth': 18, 'min_child_samples': 50, 'feature_fraction': 0.9943295733240962, 'bagging_fraction': 0.728131760785334, 'bagging_freq': 3, 'lambda_l1': 1.7497684179511237e-08, 'lambda_l2': 9.269052342453529}. Best is trial 13 with value: 1.363110560243712.\n",
      "[I 2025-09-07 19:18:13,812] Trial 14 finished with value: 1.3678774325358518 and parameters: {'learning_rate': 0.19245997693077602, 'num_leaves': 110, 'max_depth': 18, 'min_child_samples': 50, 'feature_fraction': 0.9996050818234752, 'bagging_fraction': 0.7883113201694567, 'bagging_freq': 6, 'lambda_l1': 0.0013859302788951716, 'lambda_l2': 0.015188060022818424}. Best is trial 13 with value: 1.363110560243712.\n",
      "[I 2025-09-07 19:18:13,858] Trial 15 finished with value: 1.3709413615670971 and parameters: {'learning_rate': 0.12586978593923087, 'num_leaves': 150, 'max_depth': 9, 'min_child_samples': 40, 'feature_fraction': 0.8522557608929233, 'bagging_fraction': 0.8544045337584538, 'bagging_freq': 2, 'lambda_l1': 1.1159065407040629e-08, 'lambda_l2': 0.024985018335309805}. Best is trial 13 with value: 1.363110560243712.\n",
      "[I 2025-09-07 19:18:13,894] Trial 16 finished with value: 1.367501432715662 and parameters: {'learning_rate': 0.11796940903585869, 'num_leaves': 109, 'max_depth': 18, 'min_child_samples': 50, 'feature_fraction': 0.9905851764668981, 'bagging_fraction': 0.7471644741655619, 'bagging_freq': 3, 'lambda_l1': 2.97124088262911e-07, 'lambda_l2': 1.314053143275926e-08}. Best is trial 13 with value: 1.363110560243712.\n",
      "[I 2025-09-07 19:18:13,936] Trial 17 finished with value: 1.3834341251413411 and parameters: {'learning_rate': 0.11773708052467725, 'num_leaves': 130, 'max_depth': 10, 'min_child_samples': 36, 'feature_fraction': 0.875869770084707, 'bagging_fraction': 0.7108586835160882, 'bagging_freq': 4, 'lambda_l1': 0.001456146958918749, 'lambda_l2': 9.044389534160972}. Best is trial 13 with value: 1.363110560243712.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[15]\tvalid_0's rmse: 1.36311\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[18]\tvalid_0's rmse: 1.36788\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[27]\tvalid_0's rmse: 1.37094\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[24]\tvalid_0's rmse: 1.3675\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[25]\tvalid_0's rmse: 1.38343\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-07 19:18:14,078] Trial 18 finished with value: 1.436067783260492 and parameters: {'learning_rate': 0.13940127601485922, 'num_leaves': 167, 'max_depth': 18, 'min_child_samples': 5, 'feature_fraction': 0.7810309772863404, 'bagging_fraction': 0.8366070683982902, 'bagging_freq': 2, 'lambda_l1': 3.379967785713623e-07, 'lambda_l2': 1.2602385917713332e-05}. Best is trial 13 with value: 1.363110560243712.\n",
      "[I 2025-09-07 19:18:14,126] Trial 19 finished with value: 1.385348777988294 and parameters: {'learning_rate': 0.0893942958390587, 'num_leaves': 100, 'max_depth': 11, 'min_child_samples': 45, 'feature_fraction': 0.9499737847758472, 'bagging_fraction': 0.9461214256951717, 'bagging_freq': 5, 'lambda_l1': 5.799449092292789e-05, 'lambda_l2': 0.021610874731711048}. Best is trial 13 with value: 1.363110560243712.\n",
      "[I 2025-09-07 19:18:14,167] Trial 20 finished with value: 1.3870698304192757 and parameters: {'learning_rate': 0.1592953405890677, 'num_leaves': 132, 'max_depth': 17, 'min_child_samples': 24, 'feature_fraction': 0.955841372269387, 'bagging_fraction': 0.7666431086231282, 'bagging_freq': 1, 'lambda_l1': 3.1742499660516616e-06, 'lambda_l2': 0.003261400251334937}. Best is trial 13 with value: 1.363110560243712.\n",
      "[I 2025-09-07 19:18:14,204] Trial 21 finished with value: 1.3588743427675174 and parameters: {'learning_rate': 0.10653347083414894, 'num_leaves': 97, 'max_depth': 18, 'min_child_samples': 50, 'feature_fraction': 0.9975898165325531, 'bagging_fraction': 0.7530317173264705, 'bagging_freq': 3, 'lambda_l1': 1.9048025538984172e-07, 'lambda_l2': 1.297035295058723e-08}. Best is trial 21 with value: 1.3588743427675174.\n",
      "[I 2025-09-07 19:18:14,241] Trial 22 finished with value: 1.3668851102402155 and parameters: {'learning_rate': 0.09917211000722084, 'num_leaves': 90, 'max_depth': 19, 'min_child_samples': 46, 'feature_fraction': 0.9940040995313086, 'bagging_fraction': 0.6877249415436562, 'bagging_freq': 3, 'lambda_l1': 7.640440213575826e-08, 'lambda_l2': 4.323027807245568e-08}. Best is trial 21 with value: 1.3588743427675174.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[24]\tvalid_0's rmse: 1.43607\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[37]\tvalid_0's rmse: 1.38535\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[15]\tvalid_0's rmse: 1.38707\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[27]\tvalid_0's rmse: 1.35887\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[27]\tvalid_0's rmse: 1.36689\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-07 19:18:14,283] Trial 23 finished with value: 1.3761945850116022 and parameters: {'learning_rate': 0.1893607498525961, 'num_leaves': 155, 'max_depth': 17, 'min_child_samples': 41, 'feature_fraction': 0.9194159622335092, 'bagging_fraction': 0.8219643567573005, 'bagging_freq': 2, 'lambda_l1': 4.9435567692737205e-08, 'lambda_l2': 1.1178321976911433e-05}. Best is trial 21 with value: 1.3588743427675174.\n",
      "[I 2025-09-07 19:18:14,366] Trial 24 finished with value: 1.3811717456315415 and parameters: {'learning_rate': 0.018924645553851333, 'num_leaves': 124, 'max_depth': 19, 'min_child_samples': 46, 'feature_fraction': 0.9633978700443572, 'bagging_fraction': 0.7777351385062048, 'bagging_freq': 6, 'lambda_l1': 7.474018108013456e-07, 'lambda_l2': 1.2905995891419694e-05}. Best is trial 21 with value: 1.3588743427675174.\n",
      "[I 2025-09-07 19:18:14,406] Trial 25 finished with value: 1.3795349276342461 and parameters: {'learning_rate': 0.1520104772729557, 'num_leaves': 117, 'max_depth': 15, 'min_child_samples': 36, 'feature_fraction': 0.8859603798635864, 'bagging_fraction': 0.724418466132938, 'bagging_freq': 4, 'lambda_l1': 1.514820577559844e-08, 'lambda_l2': 1.8366842606502907}. Best is trial 21 with value: 1.3588743427675174.\n",
      "[I 2025-09-07 19:18:14,457] Trial 26 finished with value: 1.373428496531469 and parameters: {'learning_rate': 0.05412459354562146, 'num_leaves': 55, 'max_depth': 19, 'min_child_samples': 50, 'feature_fraction': 0.9715947600246224, 'bagging_fraction': 0.6549157102440857, 'bagging_freq': 2, 'lambda_l1': 2.1047988554164624e-05, 'lambda_l2': 0.0877176673308064}. Best is trial 21 with value: 1.3588743427675174.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[16]\tvalid_0's rmse: 1.37619\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[162]\tvalid_0's rmse: 1.38117\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[19]\tvalid_0's rmse: 1.37953\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[72]\tvalid_0's rmse: 1.37343\n",
      "Training until validation scores don't improve for 50 rounds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-09-07 19:18:14,496] Trial 27 finished with value: 1.3762008896479814 and parameters: {'learning_rate': 0.1049491143066254, 'num_leaves': 143, 'max_depth': 17, 'min_child_samples': 46, 'feature_fraction': 0.9322158548901793, 'bagging_fraction': 0.7583459435013726, 'bagging_freq': 5, 'lambda_l1': 8.580848724117879e-08, 'lambda_l2': 1.157357885453882e-07}. Best is trial 21 with value: 1.3588743427675174.\n",
      "[I 2025-09-07 19:18:14,542] Trial 28 finished with value: 1.3758017285529167 and parameters: {'learning_rate': 0.07729046632676011, 'num_leaves': 96, 'max_depth': 15, 'min_child_samples': 42, 'feature_fraction': 0.8526333921184073, 'bagging_fraction': 0.7083878875871941, 'bagging_freq': 3, 'lambda_l1': 9.752873201333507e-07, 'lambda_l2': 4.4885788944414506e-05}. Best is trial 21 with value: 1.3588743427675174.\n",
      "[I 2025-09-07 19:18:14,575] Trial 29 finished with value: 1.369993545585721 and parameters: {'learning_rate': 0.14922007609723206, 'num_leaves': 196, 'max_depth': 17, 'min_child_samples': 36, 'feature_fraction': 0.8913013031488286, 'bagging_fraction': 0.6035149849695796, 'bagging_freq': 1, 'lambda_l1': 0.0003235688840152951, 'lambda_l2': 0.0019113887005791207}. Best is trial 21 with value: 1.3588743427675174.\n",
      "2025-09-07 19:18:14,576 - INFO - Best RMSE (cost)=23.3779 | (days)=1.3589\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping, best iteration is:\n",
      "[25]\tvalid_0's rmse: 1.3762\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[47]\tvalid_0's rmse: 1.3758\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[20]\tvalid_0's rmse: 1.36999\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[100]\tvalid_0's rmse: 0.205035\n",
      "[200]\tvalid_0's rmse: 0.154863\n",
      "[300]\tvalid_0's rmse: 0.148759\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-07 19:18:14,800 - INFO - Training carrier-specific models\n",
      "2025-09-07 19:18:14,900 - INFO - Calculating calibration factors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[400]\tvalid_0's rmse: 0.148194\n",
      "[500]\tvalid_0's rmse: 0.148012\n",
      "Early stopping, best iteration is:\n",
      "[492]\tvalid_0's rmse: 0.147902\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[27]\tvalid_0's rmse: 1.35887\n",
      "Training until validation scores don't improve for 30 rounds\n",
      "Early stopping, best iteration is:\n",
      "[122]\tvalid_0's rmse: 0.113437\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-07 19:18:14,912 - INFO - DHL cost error | mean=15.57, median=7.91, max=309.32\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[456]\tvalid_0's rmse: 0.169446\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[534]\tvalid_0's rmse: 0.160388\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[387]\tvalid_0's rmse: 0.0895428\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[618]\tvalid_0's rmse: 0.0874412\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[612]\tvalid_0's rmse: 0.158849\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-07 19:18:15,899 - INFO - CV RMSE Cost: 22.5275 ± 3.7490 | Days: 1.0155 ± 0.0572\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[67]\tvalid_0's rmse: 1.06364\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[64]\tvalid_0's rmse: 0.933507\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[57]\tvalid_0's rmse: 0.960408\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[44]\tvalid_0's rmse: 1.07249\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[45]\tvalid_0's rmse: 1.0477\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-07 19:18:16,217 - INFO - Artifacts saved to model_artifacts\n",
      "2025-09-07 19:18:16,217 - INFO - === TRAINING COMPLETED SUCCESSFULLY ===\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary: {\n",
      "  \"artifacts_dir\": \"model_artifacts\",\n",
      "  \"best_params_json\": \"model_artifacts/best_params.json\",\n",
      "  \"carrier_performance_csv\": \"model_artifacts/carrier_performance.csv\",\n",
      "  \"rmse_plot_png\": \"model_artifacts/carrier_rmse_analysis.png\",\n",
      "  \"when\": \"2025-09-08T02:18:16.218088Z\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Execute the pipeline when running the notebook programmatically\n",
    "    summary = main()\n",
    "    print(\"Summary:\", json.dumps(summary, indent=2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7430ba9-1128-4d1d-86db-989b09de6d20",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b120f603-8a0a-402d-9bf3-d658c5fc0e63",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
